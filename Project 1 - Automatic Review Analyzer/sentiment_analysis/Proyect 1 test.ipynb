{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation, digits\n",
    "import numpy as np\n",
    "import random\n",
    "import utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order(n_samples):\n",
    "    try:\n",
    "        with open(str(n_samples) + '.txt') as fp:\n",
    "            line = fp.readline()\n",
    "            return list(map(int, line.split(',')))\n",
    "    except FileNotFoundError:\n",
    "        random.seed(1)\n",
    "        indices = list(range(n_samples))\n",
    "        random.shuffle(indices)\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2], [1, 2]])\n",
    "label, theta, theta_0 = np.array([1, 1]), np.array([-1, 1]), -0.2\n",
    "exp_res = 1 - 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss_single(feature_vector, label, theta, theta_0):\n",
    "    \"\"\"\n",
    "    Finds the hinge loss on a single data point given specific classification\n",
    "    parameters.\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing the given data point.\n",
    "        label - A real valued   number, the correct classification of the data\n",
    "            point.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "\n",
    "    Returns: A real number representing the hinge loss associated with the\n",
    "    given data point and parameters.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    z = label*(np.dot(theta, feature_vector)+theta_0)\n",
    "    if z>=1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1-z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss_full(feature_matrix, labels, theta, theta_0):\n",
    "    \"\"\"\n",
    "    Finds the total hinge loss on a set of data given specific classification\n",
    "    parameters.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "\n",
    "    Returns: A real number representing the hinge loss associated with the\n",
    "    given dataset and parameters. This number should be the average hinge\n",
    "    loss across all of the points in the feature matrix.\n",
    "    \"\"\"\n",
    "    hsum = np.zeros((feature_matrix.shape[0],1))\n",
    "    # Your code here\n",
    "    for i in range(feature_matrix.shape[0]):\n",
    "            hsum[i] = hinge_loss_single(feature_matrix[i,:], labels[i], theta, theta_0)\n",
    "    return np.sum(hsum)/len(feature_matrix[0])\n",
    "    #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2], [1, 2]])\n",
    "label, theta, theta_0 = np.array([1, 1]), np.array([-1, 1]), -0.2\n",
    "exp_res = 1 - 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_loss_full(x,label, theta, theta_0) == exp_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss_full(feature_matrix, labels, theta, theta_0):\n",
    "    \"\"\"\n",
    "    Finds the total hinge loss on a set of data given specific classification\n",
    "    parameters.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "\n",
    "    Returns: A real number representing the hinge loss associated with the\n",
    "    given dataset and parameters. This number should be the average hinge\n",
    "    loss across all of the points in the feature matrix.\n",
    "    \"\"\"\n",
    "    hinge_full = 1 - (labels*(np.dot(feature_matrix, theta)+theta_0))\n",
    "    #hinge_full = np.where(hinge_full==0,1,hinge_full)\n",
    "    hinge_full[hinge_full<0]=0\n",
    "    \n",
    "    return hinge_full.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_loss_full(x,label, theta, theta_0) == exp_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello :  1     Sce : 0\n"
     ]
    }
   ],
   "source": [
    "print (\"Hello :  %d     Sce : %s\" %(1, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 2]), 0)\n",
      "(array([1, 2]), 1)\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(x,range(np.size(x,0))):\n",
    "    print((i,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_single_step_update(\n",
    "        feature_vector,\n",
    "        label,\n",
    "        current_theta,\n",
    "        current_theta_0):\n",
    "    \"\"\"\n",
    "    Properly updates the classification parameter, theta and theta_0, on a\n",
    "    single step of the perceptron algorithm.\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing a single data point.\n",
    "        label - The correct classification of the feature vector.\n",
    "        current_theta - The current theta being used by the perceptron\n",
    "            algorithm before this update.\n",
    "        current_theta_0 - The current theta_0 being used by the perceptron\n",
    "            algorithm before this update.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta after the current update has completed and the second element is a\n",
    "    real valued number with the value of theta_0 after the current updated has\n",
    "    completed.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    if (label * (np.dot(current_theta, feature_vector) + current_theta_0)) <= 0:\n",
    "        current_theta += label*feature_vector\n",
    "        current_theta_0 += label\n",
    "\n",
    "    return (current_theta, current_theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-0.40693195 , 0.48264844, -0.38956493, -0.47310565, -0.43401042,  0.36199333,\n",
    "  0.44056266, -0.29557264, -0.08417648,  0.27143027])\n",
    "y = -1\n",
    "theta = np.array([-0.351117,   -0.17636743,  0.01502589,  0.27085476 , 0.42011513,  0.20540997,\n",
    " -0.07781607 , 0.03085709 , 0.08954577 , 0.1959461 ])\n",
    "theta_0 = -0.4499382570373128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6319100897740646"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y * (np.dot(theta,x)+theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.351117  , -0.17636743,  0.01502589,  0.27085476,  0.42011513,\n",
       "         0.20540997, -0.07781607,  0.03085709,  0.08954577,  0.1959461 ]),\n",
       " -0.4499382570373128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (y * (np.dot(theta,x)+theta_0))<= 0:\n",
    "    theta += y*x\n",
    "    theta_0 += y\n",
    "theta, theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.351117  , -0.17636743,  0.01502589,  0.27085476,  0.42011513,\n",
       "         0.20540997, -0.07781607,  0.03085709,  0.08954577,  0.1959461 ]),\n",
       " -0.4499382570373128)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_single_step_update(x,y,theta,theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.40693195, -0.48264844,  0.38956493,  0.47310565,  0.43401042,\n",
       "        -0.36199333, -0.44056266,  0.29557264,  0.08417648, -0.27143027]),\n",
       " 0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta, theta_0 = np.zeros((x.shape[0],)),0\n",
    "#theta_0 = 0\n",
    "theta, theta_0 = perceptron_single_step_update(x,y,theta,theta_0)[0], perceptron_single_step_update(x,y,theta,theta_0)[1]\n",
    "theta, theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(feature_matrix, labels, T):\n",
    "    \"\"\"\n",
    "    Runs the full perceptron algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
    "\n",
    "    Args:\n",
    "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the perceptron algorithm\n",
    "            should iterate through the feature matrix.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta, the linear classification parameter, after T iterations through the\n",
    "    feature matrix and the second element is a real number with the value of\n",
    "    theta_0, the offset classification parameter, after T iterations through\n",
    "    the feature matrix.\n",
    "    \"\"\"\n",
    "    theta, theta_0 = np.zeros((feature_matrix.shape[1],)), 0\n",
    "    print(feature_matrix.shape[0])\n",
    "    # Your code here\n",
    "    for t in range(T):\n",
    "        for i in range(feature_matrix.shape[0]):\n",
    "            # Your code here\n",
    "            t = perceptron_single_step_update(feature_matrix[i, :], labels[i], theta, theta_0)\n",
    "            theta, theta_0 = t[0], t[1]\n",
    "            \n",
    "            \n",
    "            #pass\n",
    "    \n",
    "    return(theta, theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-bf760dab050c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfeature_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "theta, theta_0 = np.zeros((feature_matrix.shape[1],)), 0\n",
    "feature_matrix = np.array([[1, 2]])\n",
    "labels = np.array([1])\n",
    "T = 1\n",
    "perceptron(feature_matrix, labels, T)\n",
    "#perceptron_single_step_update(feature_matrix[i, :], labels[i], theta, theta_0), feature_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-64ef17df1c51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeature_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "feature_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-b0cfc6850fc3>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-b0cfc6850fc3>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    labels = np.array([-1  1  1  1 -1])\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "feature_matrix = np.array([[ 0.09334818 ,-0.01544469 , 0.13405622 , 0.34491817 , 0.04166459,  0.39493563,\n",
    "  -0.18338607, -0.43957034, -0.46190975, -0.24975976]\n",
    " [ 0.41657729 , 0.07569962,  0.41251052, -0.36185631, -0.12757683 , 0.06123831,\n",
    "   0.20650185 , 0.26003101, 0.069105  , -0.26563641]\n",
    " [-0.19188315,  0.21033365, -0.23713144, -0.08926778,  0.26603686 , 0.47717252,\n",
    "  -0.47867535, -0.24245049 , 0.36502655, -0.24305283]\n",
    " [-0.17016906, -0.28178701, -0.48180109,  0.13899522, -0.19500262, -0.18908814,\n",
    "   0.25368259, -0.0316778 ,  0.10088184, -0.18054423]\n",
    " [-0.27601958 ,-0.39640354, -0.25004556,  0.180031,   -0.1974046,  -0.08591306,\n",
    "  -0.1753684,  -0.12180758,  0.34427095, -0.40503603]])\n",
    "labels = np.array([-1  1  1  1 -1])\n",
    "T = 5\n",
    "perceptron(feature_matrix, labels, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_perceptron(feature_matrix, labels, T):\n",
    "    \"\"\"\n",
    "    Runs the average perceptron algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
    "\n",
    "\n",
    "    Args:\n",
    "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the perceptron algorithm\n",
    "            should iterate through the feature matrix.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    the average theta, the linear classification parameter, found after T\n",
    "    iterations through the feature matrix and the second element is a real\n",
    "    number with the value of the average theta_0, the offset classification\n",
    "    parameter, found after T iterations through the feature matrix.\n",
    "\n",
    "    Hint: It is difficult to keep a running average; however, it is simple to\n",
    "    find a sum and divide.\n",
    "    \"\"\"\n",
    "    theta, theta_0 = np.zeros((feature_matrix.shape[1],)), 0\n",
    "    sum_thetas = np.zeros(feature_matrix.shape[1],)\n",
    "    sum_thetas_0 = 0\n",
    "    n = feature_matrix.shape[0]\n",
    "    # Your code here\n",
    "    for t in range(T):\n",
    "        for i in get_order(feature_matrix.shape[0]):\n",
    "            # Your code here\n",
    "\n",
    "            t = perceptron_single_step_update(feature_matrix[i, :], labels[i], theta, theta_0)\n",
    "            theta, theta_0 = t[0], t[1]\n",
    "\n",
    "            sum_thetas += theta\n",
    "            sum_thetas_0 += theta_0\n",
    "            # pass\n",
    "    theta_avg = sum_thetas/(n*T)\n",
    "    theta_0_avg = sum_thetas_0/(n*T)\n",
    "    return (theta_avg, theta_0_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2.]), 1.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = np.array([[1, 2]])\n",
    "labels = np.array([1])\n",
    "T = 1\n",
    "average_perceptron(feature_matrix, labels, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_perceptron2(feature_matrix, labels, T):\n",
    "    theta = np.zeros(feature_matrix.shape[1], )\n",
    "    theta_0 = 0\n",
    "    \n",
    "    theta_aggregate = np.zeros(feature_matrix.shape[1], )\n",
    "    theta_0_aggregate = 0\n",
    "    \n",
    "    for t in range(T):\n",
    "        for i in get_order(feature_matrix.shape[0]):\n",
    "            theta, theta_0 = perceptron_single_step_update(feature_matrix[i], labels[i], theta, theta_0)\n",
    "            theta_aggregate += theta\n",
    "            theta_0_aggregate += theta_0\n",
    "            \n",
    "    return theta_aggregate / (feature_matrix.shape[0] * T), theta_0_aggregate / (feature_matrix.shape[0] * T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2.]), 1.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = np.array([[1, 2]])\n",
    "labels = np.array([1])\n",
    "T = 1\n",
    "average_perceptron2(feature_matrix, labels, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pegasos algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos_single_step_update(\n",
    "        feature_vector,\n",
    "        label,\n",
    "        L,\n",
    "        eta,\n",
    "        current_theta,\n",
    "        current_theta_0):\n",
    "    \"\"\"\n",
    "    Properly updates the classification parameter, theta and theta_0, on a\n",
    "    single step of the Pegasos algorithm\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing a single data point.\n",
    "        label - The correct classification of the feature vector.\n",
    "        L - The lamba value being used to update the parameters.\n",
    "        eta - Learning rate to update parameters.\n",
    "        current_theta - The current theta being used by the Pegasos\n",
    "            algorithm before this update.\n",
    "        current_theta_0 - The current theta_0 being used by the\n",
    "            Pegasos algorithm before this update.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta after the current update has completed and the second element is a\n",
    "    real valued number with the value of theta_0 after the current updated has\n",
    "    completed.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    k = 1-L*eta\n",
    "\n",
    "    if (label * (np.dot(current_theta, feature_vector) + current_theta_0)) <= 1:\n",
    "        current_theta = current_theta*k + eta*label * feature_vector\n",
    "        current_theta_0 = current_theta_0 + eta*label\n",
    "        print(1)\n",
    "\n",
    "    else:\n",
    "        current_theta = current_theta * k\n",
    "        #current_theta_0 *=k\n",
    "    return (current_theta, current_theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.88,  1.18]), -1.4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector = np.array([1, 2])\n",
    "label, theta, theta_0 = 1, np.array([-1, 1]), -1.5\n",
    "L = 0.2\n",
    "eta = 0.1\n",
    "\n",
    "pegasos_single_step_update(\n",
    "        feature_vector,\n",
    "        label,\n",
    "        L,\n",
    "        eta,\n",
    "        theta,\n",
    "        theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00860117,  0.07983306, -0.03308679, -0.05816094,  0.0051604 ,\n",
       "       -0.02766816, -0.02001426,  0.01495653,  0.00427496, -0.03441046])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector = np.array([-0.09525004, -0.46044561,  0.39957794, -0.13994223, -0.16127799, -0.24583467,\n",
    "  0.30520314, -0.43346013,  0.10093966, -0.43394943])\n",
    "label= -1\n",
    "L= 0.8226983197289679\n",
    "eta= 0.9455762122880957\n",
    "theta= np.array([-0.03873073,  0.35948524, -0.14898855, -0.26189652,  0.0232371,  -0.12458866,\n",
    " -0.09012346,  0.06734868,  0.01924999, -0.15494901])\n",
    "theta_0= -1.40455069784516\n",
    "\n",
    "#label * (np.dot(theta, feature_vector) + theta_0)\n",
    "pegasos_single_step_update(feature_vector, label, L, eta, theta, theta_0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos(feature_matrix, labels, T, L):\n",
    "    \"\"\"\n",
    "    Runs the Pegasos algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    For each update, set learning rate = 1/sqrt(t),\n",
    "    where t is a counter for the number of updates performed so far (between 1\n",
    "    and nT inclusive).\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the algorithm\n",
    "            should iterate through the feature matrix.\n",
    "        L - The lamba value being used to update the Pegasos\n",
    "            algorithm parameters.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    the theta, the linear classification parameter, found after T\n",
    "    iterations through the feature matrix and the second element is a real\n",
    "    number with the value of the theta_0, the offset classification\n",
    "    parameter, found after T iterations through the feature matrix.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    theta, theta_0 = np.zeros((feature_matrix.shape[1],)), 0\n",
    "\n",
    "    # Your code here\n",
    "    for t in range(T):\n",
    "        eta = 1/np.sqrt(t+1)\n",
    "        for i in get_order(feature_matrix.shape[0]):\n",
    "            # Your code here\n",
    "\n",
    "            t = pegasos_single_step_update(feature_matrix[i, :], L, eta, labels[i], theta, theta_0)\n",
    "            theta, theta_0 = t[0], t[1]\n",
    "            # pass\n",
    "    return (theta, theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_order(feature_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Review Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews_train.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>productId</th>\n",
       "      <th>userId</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>helpfulY</th>\n",
       "      <th>helpfulN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>B000EQYQBO</td>\n",
       "      <td>A2JZVE0Y19VLL0</td>\n",
       "      <td>blue chips</td>\n",
       "      <td>The chips are okay Not near as flavorful as th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>B000LKVHYC</td>\n",
       "      <td>A3NAKOMAS0I5L9</td>\n",
       "      <td>Bad even for 'healthy'</td>\n",
       "      <td>I had high hopes for this, but it was bad.  Re...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>B003QRQRY2</td>\n",
       "      <td>ARBO3XW14MNGA</td>\n",
       "      <td>Alot of money for one can</td>\n",
       "      <td>I guess it's only one can since there is nothi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>B008EG58V8</td>\n",
       "      <td>A1IQXGT4MJUYJ8</td>\n",
       "      <td>The Box says \"OATMEAL SQUARES\" which I believe...</td>\n",
       "      <td>\"Oatmeal Squares\" is in about the largest prin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>B004WZZY8M</td>\n",
       "      <td>A2TBL6WAZGXB9P</td>\n",
       "      <td>Delicious!</td>\n",
       "      <td>I really enjoyed this flavor, this has a very ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>-1</td>\n",
       "      <td>B0038B1DEU</td>\n",
       "      <td>A3MKRM2Q9F04UH</td>\n",
       "      <td>Great nutrititious drink for kids</td>\n",
       "      <td>I bought both the Berry and Chocolate drinks f...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>1</td>\n",
       "      <td>B0002CDZD0</td>\n",
       "      <td>A1ESH5GWEGT2ZX</td>\n",
       "      <td>SOOO GOOD FOR THE SKIN</td>\n",
       "      <td>THIS LAVENDER IS SOOO GOOD.IT LOOKS,SMELLS,TAS...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>1</td>\n",
       "      <td>B006N3I2SK</td>\n",
       "      <td>A2S0YE8GUSX20A</td>\n",
       "      <td>Deep fabulous rich decaf coffee for the Keurig</td>\n",
       "      <td>Great great decaf.  Made the Keurig worth it. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>1</td>\n",
       "      <td>B004TPUSU4</td>\n",
       "      <td>A16J5HGMGX5LWM</td>\n",
       "      <td>EXCELLENT American-made GF pasta!</td>\n",
       "      <td>Cooks up al-dente with great flavor. Doesn't f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>-1</td>\n",
       "      <td>B001TLY7BM</td>\n",
       "      <td>AKYQ59VS0B38Q</td>\n",
       "      <td>cat food</td>\n",
       "      <td>The photo presented by a reviewer convinced me...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment   productId          userId  \\\n",
       "0            -1  B000EQYQBO  A2JZVE0Y19VLL0   \n",
       "1            -1  B000LKVHYC  A3NAKOMAS0I5L9   \n",
       "2            -1  B003QRQRY2   ARBO3XW14MNGA   \n",
       "3            -1  B008EG58V8  A1IQXGT4MJUYJ8   \n",
       "4             1  B004WZZY8M  A2TBL6WAZGXB9P   \n",
       "...         ...         ...             ...   \n",
       "3995         -1  B0038B1DEU  A3MKRM2Q9F04UH   \n",
       "3996          1  B0002CDZD0  A1ESH5GWEGT2ZX   \n",
       "3997          1  B006N3I2SK  A2S0YE8GUSX20A   \n",
       "3998          1  B004TPUSU4  A16J5HGMGX5LWM   \n",
       "3999         -1  B001TLY7BM   AKYQ59VS0B38Q   \n",
       "\n",
       "                                                summary  \\\n",
       "0                                            blue chips   \n",
       "1                                Bad even for 'healthy'   \n",
       "2                             Alot of money for one can   \n",
       "3     The Box says \"OATMEAL SQUARES\" which I believe...   \n",
       "4                                            Delicious!   \n",
       "...                                                 ...   \n",
       "3995                  Great nutrititious drink for kids   \n",
       "3996                             SOOO GOOD FOR THE SKIN   \n",
       "3997     Deep fabulous rich decaf coffee for the Keurig   \n",
       "3998                  EXCELLENT American-made GF pasta!   \n",
       "3999                                           cat food   \n",
       "\n",
       "                                                   text  helpfulY  helpfulN  \n",
       "0     The chips are okay Not near as flavorful as th...         0         0  \n",
       "1     I had high hopes for this, but it was bad.  Re...         0         0  \n",
       "2     I guess it's only one can since there is nothi...         1         1  \n",
       "3     \"Oatmeal Squares\" is in about the largest prin...         0         0  \n",
       "4     I really enjoyed this flavor, this has a very ...         1         0  \n",
       "...                                                 ...       ...       ...  \n",
       "3995  I bought both the Berry and Chocolate drinks f...         4         2  \n",
       "3996  THIS LAVENDER IS SOOO GOOD.IT LOOKS,SMELLS,TAS...         1         0  \n",
       "3997  Great great decaf.  Made the Keurig worth it. ...         1         0  \n",
       "3998  Cooks up al-dente with great flavor. Doesn't f...         0         0  \n",
       "3999  The photo presented by a reviewer convinced me...         2        10  \n",
       "\n",
       "[4000 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(feature_matrix, theta, theta_0):\n",
    "    \"\"\"\n",
    "    A classification function that uses theta and theta_0 to classify a set of\n",
    "    data points.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "                theta - A numpy array describing the linear classifier.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "    Returns: A numpy array of 1s and -1s where the kth element of the array is\n",
    "    the predicted classification of the kth row of the feature matrix using the\n",
    "    given theta and theta_0. If a prediction is GREATER THAN zero, it should\n",
    "    be considered a positive classification.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    classification = np.dot(feature_matrix, theta)+theta_0\n",
    "    classification[classification > 0] = 1\n",
    "    classification[classification < 0] = -1\n",
    "\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = np.array([[1, 1], [1, 1], [1, 1]])\n",
    "theta = np.array([1, 1])\n",
    "theta_0 = 0\n",
    "\n",
    "classify(feature_matrix, theta, theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = np.array([[-1, 1]])\n",
    "theta = np.array([1, 1])\n",
    "theta_0 = 0\n",
    "exp_res = np.array([-1])\n",
    "\n",
    "classify(feature_matrix, theta, theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array([[-1, 1]]), np.array([1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(input_string):\n",
    "    \"\"\"\n",
    "    Helper function for bag_of_words()\n",
    "    Inputs a text string\n",
    "    Returns a list of lowercase words in the string.\n",
    "    Punctuation and digits are separated out into their own words.\n",
    "    \"\"\"\n",
    "    for c in punctuation + digits:\n",
    "        input_string = input_string.replace(c, ' ' + c + ' ')\n",
    "\n",
    "    return input_string.lower().split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(texts):\n",
    "    \"\"\"\n",
    "    Inputs a list of string reviews\n",
    "    Returns a dictionary of unique unigrams occurring over the input\n",
    "\n",
    "    Feel free to change this code as guided by Problem 9\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    dictionary = {} # maps word to unique index\n",
    "    for text in texts:\n",
    "        word_list = extract_words(text)\n",
    "        #print(word_list)\n",
    "        for word in word_list:\n",
    "            if word not in dictionary:\n",
    "                dictionary[word] = len(dictionary)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = 'Something s Changed with Canidae food I fed and recommended this food for several years as one of the best dry foods available. However, over the last few months (late 2007) something has changed.  My dogs experienced chronic digestive upset on the food and refused to eat it.  Upon switching to another quality food, the problems stopped.  I tried another bag last week-- same results.  Other dog owners/breeders/vets/handlers have also reported problems with Canidae foods over the past few months.  No one, including myself, has been successful in getting any sort of satisfactory reply from Canidae when asked if they had changed formulas, ingredient suppliers, etc. I am disappointed-- Canidae was one of the few quality foods that had not raised prices significantly over the past year and was still affordable for most dog owners.  Apparently that has also led to changes that the company has not been willing to address.  I am very disappointed that a food I recommended so highly in the past has had these problems.  I have changed my dogs to Eagle Pack Holistic Selects. It is more expensive, but they are back to their old selves-- healthy, no digestive troubles, and great coats.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s': 0,\n",
       " 'o': 1,\n",
       " 'm': 2,\n",
       " 'e': 3,\n",
       " 't': 4,\n",
       " 'h': 5,\n",
       " 'i': 6,\n",
       " 'n': 7,\n",
       " 'g': 8,\n",
       " 'c': 9,\n",
       " 'a': 10,\n",
       " 'd': 11,\n",
       " 'w': 12,\n",
       " 'f': 13,\n",
       " 'r': 14,\n",
       " 'v': 15,\n",
       " 'l': 16,\n",
       " 'y': 17,\n",
       " 'b': 18,\n",
       " '.': 19,\n",
       " ',': 20,\n",
       " '(': 21,\n",
       " '2': 22,\n",
       " '0': 23,\n",
       " '7': 24,\n",
       " ')': 25,\n",
       " 'x': 26,\n",
       " 'p': 27,\n",
       " 'u': 28,\n",
       " 'q': 29,\n",
       " 'k': 30,\n",
       " '-': 31,\n",
       " '/': 32}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_words(file_name):   \n",
    "    inFile = open(file_name, 'r')\n",
    "    # wordlist: list of strings\n",
    "    wordlist = []\n",
    "    for line in inFile:\n",
    "        wordlist.extend([word.lower() for word in line.split('\\n')])\n",
    "    wordlist = list(set(wordlist))\n",
    "    wordlist.remove('')\n",
    "    \n",
    "    return wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "inFile = open('stopwords.txt', 'r')\n",
    "# wordlist: list of strings\n",
    "wordlist = []\n",
    "for line in inFile:\n",
    "    wordlist.extend([word.lower() for word in line.split('\\n')])\n",
    "wordlist = list(set(wordlist))\n",
    "wordlist.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['had',\n",
       " 'her',\n",
       " 'a',\n",
       " 'were',\n",
       " 't',\n",
       " 'will',\n",
       " 'only',\n",
       " 'here',\n",
       " 'under',\n",
       " 'of',\n",
       " 'does',\n",
       " 'has',\n",
       " 'some',\n",
       " 'over',\n",
       " 'more',\n",
       " 'because',\n",
       " 'me',\n",
       " 'them',\n",
       " 'and',\n",
       " 'is',\n",
       " 'off',\n",
       " 'than',\n",
       " 'these',\n",
       " 'into',\n",
       " 'why',\n",
       " 'do',\n",
       " 'while',\n",
       " 'by',\n",
       " 'it',\n",
       " 'nor',\n",
       " 'its',\n",
       " 'after',\n",
       " 'both',\n",
       " 'any',\n",
       " 'there',\n",
       " 'being',\n",
       " 'have',\n",
       " 'few',\n",
       " 'same',\n",
       " 'she',\n",
       " 'was',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'during',\n",
       " 'so',\n",
       " 'most',\n",
       " 'my',\n",
       " 'but',\n",
       " 'are',\n",
       " 'against',\n",
       " 'ours',\n",
       " 'between',\n",
       " 'should',\n",
       " 'how',\n",
       " 'at',\n",
       " 'where',\n",
       " 'hers',\n",
       " 'each',\n",
       " 'above',\n",
       " 'with',\n",
       " 'am',\n",
       " 'herself',\n",
       " 'our',\n",
       " 'to',\n",
       " 'very',\n",
       " 'just',\n",
       " 's',\n",
       " 'now',\n",
       " 'in',\n",
       " 'once',\n",
       " 'on',\n",
       " 'the',\n",
       " 'you',\n",
       " 'having',\n",
       " 'from',\n",
       " 'ourselves',\n",
       " 'who',\n",
       " 'myself',\n",
       " 'down',\n",
       " 'then',\n",
       " 'don',\n",
       " 'him',\n",
       " 'they',\n",
       " 'through',\n",
       " 'out',\n",
       " 'further',\n",
       " 'below',\n",
       " 'own',\n",
       " 'whom',\n",
       " 'an',\n",
       " 'i',\n",
       " 'doing',\n",
       " 'be',\n",
       " 'about',\n",
       " 'as',\n",
       " 'until',\n",
       " 'all',\n",
       " 'which',\n",
       " 'for',\n",
       " 'theirs',\n",
       " 'when',\n",
       " 'such',\n",
       " 'other',\n",
       " 'their',\n",
       " 'did',\n",
       " 'we',\n",
       " 'yours',\n",
       " 'what',\n",
       " 'this',\n",
       " 'been',\n",
       " 'can',\n",
       " 'if',\n",
       " 'himself',\n",
       " 'those',\n",
       " 'too',\n",
       " 'up',\n",
       " 'before',\n",
       " 'itself',\n",
       " 'no',\n",
       " 'or',\n",
       " 'not',\n",
       " 'his',\n",
       " 'that',\n",
       " 'again',\n",
       " 'he',\n",
       " 'themselves',\n",
       " 'your']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = load_words('stopwords.txt')\n",
    "wordlist = list(set(wordlist))\n",
    "wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['had',\n",
       " 'her',\n",
       " 'a',\n",
       " 'were',\n",
       " 't',\n",
       " 'will',\n",
       " 'only',\n",
       " 'here',\n",
       " 'under',\n",
       " 'of',\n",
       " 'does',\n",
       " 'has',\n",
       " 'some',\n",
       " 'over',\n",
       " 'more',\n",
       " 'because',\n",
       " 'me',\n",
       " 'them',\n",
       " 'and',\n",
       " 'is',\n",
       " 'off',\n",
       " 'than',\n",
       " 'these',\n",
       " 'into',\n",
       " 'why',\n",
       " 'do',\n",
       " 'while',\n",
       " 'by',\n",
       " 'it',\n",
       " 'nor',\n",
       " 'its',\n",
       " 'after',\n",
       " 'both',\n",
       " 'any',\n",
       " 'there',\n",
       " 'being',\n",
       " 'have',\n",
       " 'few',\n",
       " 'same',\n",
       " 'she',\n",
       " 'was',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'during',\n",
       " 'so',\n",
       " 'most',\n",
       " 'my',\n",
       " 'but',\n",
       " 'are',\n",
       " 'against',\n",
       " 'ours',\n",
       " 'between',\n",
       " 'should',\n",
       " 'how',\n",
       " 'at',\n",
       " 'where',\n",
       " 'hers',\n",
       " 'each',\n",
       " 'above',\n",
       " 'with',\n",
       " 'am',\n",
       " 'herself',\n",
       " 'our',\n",
       " 'to',\n",
       " 'very',\n",
       " 'just',\n",
       " 's',\n",
       " 'now',\n",
       " 'in',\n",
       " 'once',\n",
       " 'on',\n",
       " 'the',\n",
       " 'you',\n",
       " 'having',\n",
       " 'from',\n",
       " 'ourselves',\n",
       " 'who',\n",
       " 'myself',\n",
       " 'down',\n",
       " 'then',\n",
       " 'don',\n",
       " 'him',\n",
       " 'they',\n",
       " 'through',\n",
       " 'out',\n",
       " 'further',\n",
       " 'below',\n",
       " 'own',\n",
       " 'whom',\n",
       " 'an',\n",
       " 'i',\n",
       " 'doing',\n",
       " 'be',\n",
       " 'about',\n",
       " 'as',\n",
       " 'until',\n",
       " 'all',\n",
       " 'which',\n",
       " 'for',\n",
       " 'theirs',\n",
       " 'when',\n",
       " 'such',\n",
       " 'other',\n",
       " 'their',\n",
       " 'did',\n",
       " 'we',\n",
       " 'yours',\n",
       " 'what',\n",
       " 'this',\n",
       " 'been',\n",
       " 'can',\n",
       " 'if',\n",
       " 'himself',\n",
       " 'those',\n",
       " 'too',\n",
       " 'up',\n",
       " 'before',\n",
       " 'itself',\n",
       " 'no',\n",
       " 'or',\n",
       " 'not',\n",
       " 'his',\n",
       " 'that',\n",
       " 'again',\n",
       " 'he',\n",
       " 'themselves',\n",
       " 'your']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
